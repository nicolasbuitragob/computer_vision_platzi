{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cca676e-4c47-4f8b-9352-733f68ab8544",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import json\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26fc7cbf-a942-4c5a-a229-73c34391e830",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/media/nicolas/Lenovo/Projects/computer_vision_platzi/input'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd177c39-73e6-4611-8f86-ad0988f60697",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = os.path.join(data_path,'train')\n",
    "test_data = os.path.join(data_path,'test')\n",
    "json_train = os.path.join(data_path,'train.json')\n",
    "json_test = os.path.join(data_path,'test.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c20b499-2544-4539-aa92-cf90816da0da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/media/nicolas/Lenovo/Projects/computer_vision_platzi/input/train'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fff7fdfc-b957-43e3-b4c7-36d4fa1512e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = open(json_test)\n",
    "data = json.load(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4c78eaa-8b42-4ffd-aed6-edd80facc8e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '948bc033-b0e6-45e0-aded-dd7009bd4c9568f05fb5-7b46-4036-99b0-f63252838ac1',\n",
       " 'image': '39339a1089.jpg',\n",
       " 'width': 640,\n",
       " 'height': 478,\n",
       " 'segmentation_url': '',\n",
       " 'classification': [],\n",
       " 'tags': [{'parent': None,\n",
       "   'color': '#4ecc5e',\n",
       "   'pos': {'x': 49, 'y': 6, 'w': 493, 'h': 453},\n",
       "   'classes': [],\n",
       "   'name': 'motorbike',\n",
       "   'id': '6eedae51-0bbf-4862-b974-b1fb5e21fd93',\n",
       "   'text': None,\n",
       "   'type': 'bounding_box'}]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2e66c99c-ebf5-4e56-b28f-9f8c8dca9760",
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_to_csv(json_file,type_file):\n",
    "    data = open(json_file)\n",
    "    data = json.load(data)\n",
    "    csv_list = []\n",
    "    for obj in data:\n",
    "        width, height = obj['width'], obj['height']\n",
    "        img_name = obj['image']\n",
    "        for item in obj['tags']:\n",
    "            class_name = item['name']\n",
    "            xmin = item['pos']['x']\n",
    "            ymin = item['pos']['y']\n",
    "            ymax = item['pos']['y'] + item['pos']['h']\n",
    "            xmax = item['pos']['x'] + item['pos']['w']\n",
    "            value = (img_name,width,height,class_name,xmin,ymin,xmax,ymax)\n",
    "        csv_list.append(value)\n",
    "    df = pd.DataFrame(csv_list, columns = ['filename','width','height','class','xmin','ymin','xmax','ymax'])\n",
    "    path = f'{data_path}/{type_file}/labels_{type_file}.csv'\n",
    "    df.to_csv(path,index = False) \n",
    "    return path\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "05c4241b-803a-4f41-8676-4260924d9700",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_train = json_to_csv(json_train,'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "41f3dee2-806c-4086-98e6-51a076410fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_test = json_to_csv(json_test,'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a3071ac5-b7f8-45bb-a671-5113209c132e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created the TFRecords: test.record\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Usage:\n",
    "\n",
    "# Create train data:\n",
    "python generate_tfrecord.py --label=<LABEL> --csv_input=<PATH_TO_ANNOTATIONS_FOLDER>/train_labels.csv  --output_path=<PATH_TO_ANNOTATIONS_FOLDER>/train.record\n",
    "\n",
    "# Create test data:\n",
    "python generate_tfrecord.py --label=<LABEL> --csv_input=<PATH_TO_ANNOTATIONS_FOLDER>/test_labels.csv  --output_path=<PATH_TO_ANNOTATIONS_FOLDER>/test.record\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import absolute_import\n",
    "\n",
    "import os\n",
    "import io\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "sys.path.append(\"../../models/research\")\n",
    "\n",
    "from PIL import Image\n",
    "from object_detection.utils import dataset_util\n",
    "from collections import namedtuple, OrderedDict\n",
    "\n",
    "# TO-DO replace this with label map\n",
    "# for multiple labels add more else if statements\n",
    "def class_text_to_int(row_label):\n",
    "    if row_label == 'motorbike':  # 'ship':\n",
    "        return 1\n",
    "    elif row_label == 'car':\n",
    "        return 2\n",
    "    else:\n",
    "        None\n",
    "\n",
    "\n",
    "def split(df, group):\n",
    "    data = namedtuple('data', ['filename', 'object'])\n",
    "    gb = df.groupby(group)\n",
    "    return [data(filename, gb.get_group(x)) for filename, x in zip(gb.groups.keys(), gb.groups)]\n",
    "\n",
    "\n",
    "def create_tf_example(group, path):\n",
    "    with tf.io.gfile.GFile(os.path.join(path, '{}'.format(group.filename)), 'rb') as fid:\n",
    "        encoded_jpg = fid.read()\n",
    "    encoded_jpg_io = io.BytesIO(encoded_jpg)\n",
    "    image = Image.open(encoded_jpg_io)\n",
    "    width, height = image.size\n",
    "\n",
    "    filename = group.filename.encode('utf8')\n",
    "    image_format = b'jpg'\n",
    "    # check if the image format is matching with your images.\n",
    "    xmins = []\n",
    "    xmaxs = []\n",
    "    ymins = []\n",
    "    ymaxs = []\n",
    "    classes_text = []\n",
    "    classes = []\n",
    "\n",
    "    for index, row in group.object.iterrows():\n",
    "        xmins.append(row['xmin'] / width)\n",
    "        xmaxs.append(row['xmax'] / width)\n",
    "        ymins.append(row['ymin'] / height)\n",
    "        ymaxs.append(row['ymax'] / height)\n",
    "        classes_text.append(row['class'].encode('utf8'))\n",
    "        classes.append(class_text_to_int(row['class']))\n",
    "\n",
    "    tf_example = tf.train.Example(features=tf.train.Features(feature={\n",
    "        'image/height': dataset_util.int64_feature(height),\n",
    "        'image/width': dataset_util.int64_feature(width),\n",
    "        'image/filename': dataset_util.bytes_feature(filename),\n",
    "        'image/source_id': dataset_util.bytes_feature(filename),\n",
    "        'image/encoded': dataset_util.bytes_feature(encoded_jpg),\n",
    "        'image/format': dataset_util.bytes_feature(image_format),\n",
    "        'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n",
    "        'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n",
    "        'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n",
    "        'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n",
    "        'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
    "        'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
    "    }))\n",
    "    return tf_example\n",
    "\n",
    "\n",
    "output_path = 'test.record'\n",
    "csv_input = f\"{data_path}/labels_test.csv\"\n",
    "writer = tf.io.TFRecordWriter(output_path)\n",
    "path = os.path.join(test_data)\n",
    "examples = pd.read_csv(csv_input)\n",
    "grouped = split(examples, 'filename')\n",
    "for group in grouped:\n",
    "    tf_example = create_tf_example(group, path)\n",
    "    writer.write(tf_example.SerializeToString())\n",
    "\n",
    "writer.close()\n",
    "output_path = os.path.join(output_path)\n",
    "print('Successfully created the TFRecords: {}'.format(output_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb543bb9-7bac-4bff-b343-e048b8c9dc3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf7a892-896b-42c0-97d1-ec7c5451491e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4b3e08-68ea-4e95-8e89-1342780a1e2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26c534c-f0dd-4d94-a481-f8bac7a3f03b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318c3fe3-6d04-4189-b1ea-c133ae37b6da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
